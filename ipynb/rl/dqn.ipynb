{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBJeOydzQ6jAyfYnCUNnz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komo135/forex-prediction/blob/master/ipynb/rl/dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtJ6_QRbHucx",
        "outputId": "6d3bcc20-ef98-4f11-ed41-42c3606c17cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nPAcy7EKniBL",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LBbFS0xIHubh",
        "outputId": "dd0e1445-d447-445d-bcef-32b5a52c00c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%cd /content/drive/My Drive\n",
        "\n",
        "try:\n",
        "  import imp\n",
        "  imp.reload(dqn)\n",
        "except:\n",
        "  import dqn\n",
        "\n",
        "agent = dqn.Agent(restore=True, n=4, lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eG6AXzJYNXt5",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "\n",
        "agent.run(train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqg6ocmoPfbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "# agent.test(spread=10, pip_cost=1000, los_cut=150,test_data=not True)\n",
        "for _ in range(1):\n",
        "  tree_idx, replay = agent.memory.sample(128)\n",
        "\n",
        "  states = np.array([a[0][0] for a in replay], np.float32)\n",
        "  new_states = np.array([a[0][3] for a in replay], np.float32)\n",
        "  actions = np.array([a[0][1] for a in replay])\n",
        "  rewards = np.array([a[0][2] for a in replay], np.float32).reshape((-1, 1))\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    q = agent.model(states)\n",
        "    target_q = agent.target_model(new_states).numpy()\n",
        "    arg_q = agent.model(new_states).numpy()\n",
        "    random = np.random.rand(actions.shape[0])\n",
        "    arg_q = np.argmax(arg_q, -1)\n",
        "    # arg_q = np.array([np.argmax(arg_q[i]) if random[i] > 0.1 else np.random.randint(arg_q.shape[1]) for i in range(arg_q.shape[0])])\n",
        "\n",
        "    q_backup = q.numpy()\n",
        "\n",
        "    for i in range(len(rewards)):\n",
        "        # q_backup[i, actions[i]] = rewards[i] if I < 1010 and not self.restore else rewards[i] + 0.2 * target_q[i, np.argmax(arg_q[i])]\n",
        "        q_backup[i, actions[i]] = rewards[i] + 0.1 * target_q[i, arg_q[i]]\n",
        "    mse = tf.reduce_mean(tf.reduce_sum(tf.abs(q_backup - q) ** 1.5, -1))\n",
        "\n",
        "  ae = np.array([sum(i) for i in np.abs(q_backup - q.numpy())])\n",
        "  agent.memory.batch_update(tree_idx, ae)\n",
        "\n",
        "  gradients = tape.gradient(mse, agent.model.trainable_variables)\n",
        "  # gradients = [(tf.clip_by_value(grad, -10.0, 10.0))\n",
        "  #                                   for grad in gradients]\n",
        "  # agent.model.optimizer.apply_gradients(zip(gradients,agent.model.trainable_variables))\n",
        "  # print(np.mean(ae))\n",
        "  # print(q[0:5])\n",
        "  print(mse)\n",
        "print(q)\n",
        "# print(np.mean(rewards)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Au3jA6jPjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h41S2TAuwFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = model((224,224,3), 100)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}